{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Artigo 4 - Identificador de Spam\n\n\n## Autor\nNome: Danilo César Tertuliano Melo\n\nMatricula: 221031149\n\nGithub: DaniloCTM\n\n----\n\n## Objetivo\nEste artigo aplica conceitos e técnicas de processamento de linguagem natural para identificar se as mensagens são spam ou não.\n\n----","metadata":{}},{"cell_type":"markdown","source":"# Passo 1 - Configurando o Ambiente","metadata":{}},{"cell_type":"markdown","source":"Nessa etapa instalamos as bibliotecas pandas e numpy, e definimos os principais caminhos para os arquivos com os dados de treino e teste.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:10.580602Z","iopub.execute_input":"2023-05-16T22:25:10.581055Z","iopub.status.idle":"2023-05-16T22:25:10.600336Z","shell.execute_reply.started":"2023-05-16T22:25:10.581018Z","shell.execute_reply":"2023-05-16T22:25:10.599205Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"base_path = '/kaggle/input/email-classification-nlp'\ntrain_df = f'{base_path}/SMS_train.csv'\ntest_df = f'{base_path}/SMS_test.csv'","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:10.760764Z","iopub.execute_input":"2023-05-16T22:25:10.761135Z","iopub.status.idle":"2023-05-16T22:25:10.769288Z","shell.execute_reply.started":"2023-05-16T22:25:10.761101Z","shell.execute_reply":"2023-05-16T22:25:10.768239Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Passo 2 - Organizando o Dataset","metadata":{}},{"cell_type":"markdown","source":"Utilizamos o pandas para ler os arquivos csv do dataset e definimos o encoding como latin-1 para remover alguns caracteres especiais","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(train_df,encoding='latin-1')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:11.170840Z","iopub.execute_input":"2023-05-16T22:25:11.171357Z","iopub.status.idle":"2023-05-16T22:25:11.217986Z","shell.execute_reply.started":"2023-05-16T22:25:11.171320Z","shell.execute_reply":"2023-05-16T22:25:11.214970Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Aqui realizamos algumas mudanças no dataset, primeiro passamos os valores de \"Non-Spam\" para 0 e os de \"Spam\" para 1. Em seguida criamos a coluna de input com os dados da mensagem.","metadata":{}},{"cell_type":"code","source":"train_df['Label'] =  train_df['Label'].map({\"Non-Spam\":0.0,\"Spam\":1.0})\ntrain_df['input'] = 'MESSAGE: ' + train_df.Message_body","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:11.441029Z","iopub.execute_input":"2023-05-16T22:25:11.441557Z","iopub.status.idle":"2023-05-16T22:25:11.458697Z","shell.execute_reply.started":"2023-05-16T22:25:11.441518Z","shell.execute_reply":"2023-05-16T22:25:11.457444Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:11.576167Z","iopub.execute_input":"2023-05-16T22:25:11.576609Z","iopub.status.idle":"2023-05-16T22:25:11.600144Z","shell.execute_reply.started":"2023-05-16T22:25:11.576581Z","shell.execute_reply":"2023-05-16T22:25:11.599238Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   S. No.                                       Message_body  Label  \\\n0       1                         Rofl. Its true to its name    0.0   \n1       2  The guy did some bitching but I acted like i'd...    0.0   \n2       3  Pity, * was in mood for that. So...any other s...    0.0   \n3       4               Will ü b going to esplanade fr home?    0.0   \n4       5  This is the 2nd time we have tried 2 contact u...    1.0   \n\n                                               input  \n0                MESSAGE: Rofl. Its true to its name  \n1  MESSAGE: The guy did some bitching but I acted...  \n2  MESSAGE: Pity, * was in mood for that. So...an...  \n3      MESSAGE: Will ü b going to esplanade fr home?  \n4  MESSAGE: This is the 2nd time we have tried 2 ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>S. No.</th>\n      <th>Message_body</th>\n      <th>Label</th>\n      <th>input</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Rofl. Its true to its name</td>\n      <td>0.0</td>\n      <td>MESSAGE: Rofl. Its true to its name</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n      <td>0.0</td>\n      <td>MESSAGE: The guy did some bitching but I acted...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n      <td>0.0</td>\n      <td>MESSAGE: Pity, * was in mood for that. So...an...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Will ü b going to esplanade fr home?</td>\n      <td>0.0</td>\n      <td>MESSAGE: Will ü b going to esplanade fr home?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n      <td>1.0</td>\n      <td>MESSAGE: This is the 2nd time we have tried 2 ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Passo 3 - Fazendo a Tokenização","metadata":{}},{"cell_type":"markdown","source":"Inicialmente passamos o data frame para o formato de dataset do hugging face","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset,DatasetDict\n\nds = Dataset.from_pandas(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:12.007985Z","iopub.execute_input":"2023-05-16T22:25:12.008349Z","iopub.status.idle":"2023-05-16T22:25:13.277416Z","shell.execute_reply.started":"2023-05-16T22:25:12.008319Z","shell.execute_reply":"2023-05-16T22:25:13.276195Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Aqui podemos ver algumas informações gerais sobre o dataset, como as colunas e o número de linhas.","metadata":{}},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:13.279536Z","iopub.execute_input":"2023-05-16T22:25:13.280184Z","iopub.status.idle":"2023-05-16T22:25:13.287476Z","shell.execute_reply.started":"2023-05-16T22:25:13.280148Z","shell.execute_reply":"2023-05-16T22:25:13.286416Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['S. No.', 'Message_body', 'Label', 'input'],\n    num_rows: 957\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Agora selecionamos o modelo, usar um modelo muito pesado pode causar problemas caso o seu ambiente não tenha recursos o suficiente. É possível encontrar modelos que foram treinados para problemas semelhantes ao seu na Hugging Face. Para essa aplicação foi utilizado o modelo deberta-v3-small.","metadata":{}},{"cell_type":"code","source":"model_nm = 'microsoft/deberta-v3-small'","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:13.289176Z","iopub.execute_input":"2023-05-16T22:25:13.289834Z","iopub.status.idle":"2023-05-16T22:25:13.298015Z","shell.execute_reply.started":"2023-05-16T22:25:13.289798Z","shell.execute_reply":"2023-05-16T22:25:13.296670Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"É realizado o download do vocabulário e dos detalhes do modelo que escolhemos.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification,AutoTokenizer\ntokz = AutoTokenizer.from_pretrained(model_nm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Em seguida utlizamos uma linha do dataset para ver como funciona a tokenização. (É possível perceber que esse modelo separa as palavras por '_')","metadata":{}},{"cell_type":"code","source":"tokz.tokenize(\"Will ü b going to esplanade fr home?\")","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:17.754220Z","iopub.execute_input":"2023-05-16T22:25:17.754763Z","iopub.status.idle":"2023-05-16T22:25:17.765893Z","shell.execute_reply.started":"2023-05-16T22:25:17.754713Z","shell.execute_reply":"2023-05-16T22:25:17.764994Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['▁Will',\n '▁ü',\n '▁b',\n '▁going',\n '▁to',\n '▁es',\n 'plan',\n 'ade',\n '▁fr',\n '▁home',\n '?']"},"metadata":{}}]},{"cell_type":"markdown","source":"Durante o processo de tokenização, a frase é dividida em tokens, que são unidades menores de texto, geralmente palavras, subpalavras ou caracteres. A tokenização é realizada com base no vocabulário do modelo em uso. Se uma palavra estiver presente no vocabulário, ela será representada por um único token. No entanto, se uma palavra não existir no vocabulário do modelo, ela será dividida em partes menores, para que possa ser representada.\n\nComo mostrado no exemplo a palavra \"esplande\", não está presente no vocabulário do modelo, então ele divide ela em palavras menores. É assim que o modelo lida com palavras desconhecidas.","metadata":{}},{"cell_type":"markdown","source":"Agora realizamos a tokenização de todo o dataset de treino e é atribuido um index para cada palavra do vocabulário, assim podemos representar os tokens de forma numérica.","metadata":{}},{"cell_type":"code","source":"#Função para realizar a tokenização da coluna input\ndef tok_func(x): return tokz(x[\"input\"])\n\ntok_ds = ds.map(tok_func, batched=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualizamos como os dados ficam.","metadata":{}},{"cell_type":"code","source":"row = tok_ds[0]\nrow['input'], row['input_ids']","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:17.941185Z","iopub.execute_input":"2023-05-16T22:25:17.941499Z","iopub.status.idle":"2023-05-16T22:25:17.949420Z","shell.execute_reply.started":"2023-05-16T22:25:17.941472Z","shell.execute_reply":"2023-05-16T22:25:17.948300Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"('MESSAGE: Rofl. Its true to its name',\n [1, 81360, 294, 11288, 20516, 260, 2952, 980, 264, 359, 601, 2])"},"metadata":{}}]},{"cell_type":"code","source":"#Aparentemente os modelos do hugging face precisam que o campo do resultado se chame labels\ntok_ds = tok_ds.rename_columns({'Label':'labels'})","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:17.951028Z","iopub.execute_input":"2023-05-16T22:25:17.951776Z","iopub.status.idle":"2023-05-16T22:25:17.960747Z","shell.execute_reply.started":"2023-05-16T22:25:17.951705Z","shell.execute_reply":"2023-05-16T22:25:17.959783Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"----\n\n# Passo 4 - Definindo a Métrica","metadata":{}},{"cell_type":"markdown","source":"Agora definimos a metrica que será utilizada para calcular o desempenho do modelo, nesse caso utilizamos a correlação de Pearson que foi apresentada pelo Jeremy durante a lição 4.","metadata":{}},{"cell_type":"code","source":"def corr(x,y): return np.corrcoef(x,y)[0][1]","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:17.962322Z","iopub.execute_input":"2023-05-16T22:25:17.963116Z","iopub.status.idle":"2023-05-16T22:25:17.969204Z","shell.execute_reply.started":"2023-05-16T22:25:17.963084Z","shell.execute_reply":"2023-05-16T22:25:17.968163Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:17.970611Z","iopub.execute_input":"2023-05-16T22:25:17.971446Z","iopub.status.idle":"2023-05-16T22:25:17.978675Z","shell.execute_reply.started":"2023-05-16T22:25:17.971412Z","shell.execute_reply":"2023-05-16T22:25:17.977700Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"-----------\n\n# Passo 5 - dividindo os DataSets","metadata":{}},{"cell_type":"markdown","source":"Nessa etapa é importante entender a diferença entre os tipos de datasets:\n* Dataset de treino: utilizado pelo modelo durante o processo de treinamento, é com ele que o modelo aprende.\n* Dataset de validação: Esse dataset também é utilizado durante o treinamento, mas o modelo não aprende com ele, é usado apenas para ver como está o desempenho do modelo para dados diferentes.\n* Dataset de teste: É utilizado quando o modelo já está pronto, esse dado serve para comprovar que o modelo está funcionando.","metadata":{}},{"cell_type":"code","source":"dds = tok_ds.train_test_split(0.20, seed=42)\ndds","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:17.982925Z","iopub.execute_input":"2023-05-16T22:25:17.983797Z","iopub.status.idle":"2023-05-16T22:25:17.998131Z","shell.execute_reply.started":"2023-05-16T22:25:17.983763Z","shell.execute_reply":"2023-05-16T22:25:17.997306Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['S. No.', 'Message_body', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 765\n    })\n    test: Dataset({\n        features: ['S. No.', 'Message_body', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 192\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"-------------\n\n# Passo 6 - Realizando o Treinamento","metadata":{}},{"cell_type":"markdown","source":"Começamos importando alguns elementos da biblioteca transformers do Hugging Face.","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments,Trainer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Agora definimos algumas configurações para o treinamento:\n*     batch size: Onde escolhemos o tamanho do batch para que os dados sejam processados de forma paralela (O uso de um valor muito alto pode resultar em um erro devido a falta de memória da gpu).\n*     epochs: Aqui escolhemos a quantidade de épocas que o modelo será treinado.\n*     learning rate: Aqui escolhemos a taxa de aprendizado do modelo.","metadata":{}},{"cell_type":"code","source":"bs = 32 #definindo o tamanho do batch\nepochs = 4 #quantidade de épocas\nlr = 8e-5 # taxa de aprendizado","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:27.449335Z","iopub.execute_input":"2023-05-16T22:25:27.449690Z","iopub.status.idle":"2023-05-16T22:25:27.455531Z","shell.execute_reply.started":"2023-05-16T22:25:27.449654Z","shell.execute_reply":"2023-05-16T22:25:27.454621Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Passamos os dados definidos acima para o TrainingArguments","metadata":{}},{"cell_type":"code","source":"args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:27.457299Z","iopub.execute_input":"2023-05-16T22:25:27.458065Z","iopub.status.idle":"2023-05-16T22:25:27.503649Z","shell.execute_reply.started":"2023-05-16T22:25:27.458026Z","shell.execute_reply":"2023-05-16T22:25:27.502738Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Criamos o modelo e definimos o dataset de treino e o de teste. O Trainer funciona de forma semelhante ao Learner do fastai.","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                  tokenizer=tokz, compute_metrics=corr_d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Realizamos o treinamento usando o método .train()","metadata":{}},{"cell_type":"code","source":"trainer.train();","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:35.489151Z","iopub.execute_input":"2023-05-16T22:25:35.489547Z","iopub.status.idle":"2023-05-16T22:25:54.651299Z","shell.execute_reply.started":"2023-05-16T22:25:35.489509Z","shell.execute_reply":"2023-05-16T22:25:54.650206Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nYou're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [96/96 00:17, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.033822</td>\n      <td>0.927494</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.007051</td>\n      <td>0.966755</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.011051</td>\n      <td>0.950428</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.007810</td>\n      <td>0.963412</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"----\n# Passo 7 - Configurando o dataset de teste","metadata":{}},{"cell_type":"markdown","source":"Repetimos a etapa de ler o csv, criar a coluna de input e fazer a tokenização dos dados.","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(test_df,encoding='latin-1')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:54.660502Z","iopub.execute_input":"2023-05-16T22:25:54.661203Z","iopub.status.idle":"2023-05-16T22:25:54.679817Z","shell.execute_reply.started":"2023-05-16T22:25:54.661165Z","shell.execute_reply":"2023-05-16T22:25:54.678986Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_df['input'] = 'MESSAGE: ' + test_df.Message_body","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:54.680936Z","iopub.execute_input":"2023-05-16T22:25:54.681812Z","iopub.status.idle":"2023-05-16T22:25:54.687357Z","shell.execute_reply.started":"2023-05-16T22:25:54.681776Z","shell.execute_reply":"2023-05-16T22:25:54.686307Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"eval_ds = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:54.688762Z","iopub.execute_input":"2023-05-16T22:25:54.689126Z","iopub.status.idle":"2023-05-16T22:25:54.698902Z","shell.execute_reply.started":"2023-05-16T22:25:54.689095Z","shell.execute_reply":"2023-05-16T22:25:54.698072Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"eval_tok_ds = eval_ds.map(tok_func, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:25:54.700404Z","iopub.execute_input":"2023-05-16T22:25:54.701018Z","iopub.status.idle":"2023-05-16T22:25:54.755059Z","shell.execute_reply.started":"2023-05-16T22:25:54.700982Z","shell.execute_reply":"2023-05-16T22:25:54.754191Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fab507ded64e419d9a882c290f5cbf61"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Passo 8 - Fazendo a Predição","metadata":{}},{"cell_type":"markdown","source":"Fazemos a predição no dataset de teste. Nessa predição o modelo retorna o número 1 para Spam e 0 para Non-Spam.","metadata":{}},{"cell_type":"code","source":"preds = trainer.predict(eval_tok_ds).predictions.astype(int)\npreds","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:47:19.177250Z","iopub.execute_input":"2023-05-16T21:47:19.178185Z","iopub.status.idle":"2023-05-16T21:47:19.376359Z","shell.execute_reply.started":"2023-05-16T21:47:19.178152Z","shell.execute_reply":"2023-05-16T21:47:19.375161Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([[1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Agora passamos os valores de volta para string e comparamos o valor obtido com os valores esperados.","metadata":{}},{"cell_type":"code","source":"preds_results = []\nfor i in preds:\n    if i == 1:\n        preds_results.append('Spam')\n    else:\n        preds_results.append('Non-Spam')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:47:19.378236Z","iopub.execute_input":"2023-05-16T21:47:19.378738Z","iopub.status.idle":"2023-05-16T21:47:19.385143Z","shell.execute_reply.started":"2023-05-16T21:47:19.378697Z","shell.execute_reply":"2023-05-16T21:47:19.384121Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"test_results = []\nfor i in test_df['Label']:\n    test_results.append(i)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:47:19.386819Z","iopub.execute_input":"2023-05-16T21:47:19.387540Z","iopub.status.idle":"2023-05-16T21:47:19.396049Z","shell.execute_reply.started":"2023-05-16T21:47:19.387504Z","shell.execute_reply":"2023-05-16T21:47:19.395151Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"wrongs = 0 \nfor i in range(len(preds_results)):\n    if preds_results[i] != test_results[i]:\n        wrongs += 1\n        print(f'{i}|{preds_results[i]} != {test_results[i]} ')\nprint(f'\\nTaxa de erro: {(wrongs/125)*100}%')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:02:00.345984Z","iopub.execute_input":"2023-05-16T22:02:00.346966Z","iopub.status.idle":"2023-05-16T22:02:00.356106Z","shell.execute_reply.started":"2023-05-16T22:02:00.346930Z","shell.execute_reply":"2023-05-16T22:02:00.355120Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"32|Non-Spam != Spam \n34|Non-Spam != Spam \n51|Non-Spam != Spam \n55|Non-Spam != Spam \n57|Non-Spam != Spam \n64|Non-Spam != Spam \n\nTaxa de erro: 4.8%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Deploy do Modelo","metadata":{}},{"cell_type":"markdown","source":"Na etapa final realizamos o login no huggingface e subimos o nosso modelo já treinado para realizar as predições.","metadata":{}},{"cell_type":"code","source":"pip install --upgrade huggingface_hub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:44:21.862980Z","iopub.execute_input":"2023-05-16T21:44:21.863349Z","iopub.status.idle":"2023-05-16T21:44:21.872290Z","shell.execute_reply.started":"2023-05-16T21:44:21.863322Z","shell.execute_reply":"2023-05-16T21:44:21.871377Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi\napi = HfApi()\napi.create_repo(repo_id=\"lesson-4\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub(\"lesson-4\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Para acessar o modelo clique [aqui](https://huggingface.co/DaniloTertu/outputs?text=I+like+you.+I+love+you).","metadata":{}},{"cell_type":"markdown","source":"# Conclusão\n\nO modelo consegui performar bem tendo em vista que a quantidade de dados é relativamente pequena. Ele teve uma taxa de acerto de 95,2% nos dados de teste. O modelo teve uma grande melhora da primeira época para a segunda, depois disso ele não mudou muito. Após alguns testes no Hugging Face foi possível perceber que o quando o resultado é <0.6 a mensagem não é spam, já quando é >0.6 é spam. Além disso, os valores de não spam ficam muito próximos de 0.5 e os de spam ficam muito próximos de 0.75.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}